---
layout: default
---

### En este artículo contamos los esfuerzos que estamos haciendo desde el Ontology Engineering Group de la Universidad Politécnica de Madrid para intentar dar a la comunidad científica y terapéutica respuestas a algunas de sus preguntas, que pueden ser encontradas en la literatura científica que se ha publicado sobre el COVID-19

Desde hace unas semanas, el Allen Institute for Artificial Intelligence mantiene un [corpus actualizado de artículos científicos sobre COVID-19](https://pages.semanticscholar.org/coronavirus-research). A fecha de hoy (27 de marzo de 2020) este corpus contiene más de 44.000 artículos en inglés, con el texto completo de más de 29.000 artículos.

Esta ingente cantidad de literatura científica que se ha generado en apenas unos meses desde la aparición del virus demuestra la gran actividad que se ha generado desde el punto de vista científico para su estudio. Pero al mismo tiempo, es tan grande que se ha convertido en un problema para poder encontrar información específica sobre un tipo de tratamiento que se ha probado en algún grupo específico de la población, relaciones entre tratamientos, resultados obtenidos, etc. Esto es lo que normalmente se conoce como sobrecarga de información.

El 16 de marzo del 2020, la Oficina de Política Científica y Tecnológica de la Casa Blanca realizó un llamamiento a la comunidad internacional de Inteligencia Artificial para el desarrollo de técnicas de procesamiento de lenguaje natural y minería de textos que permitieran resolver [preguntas que la comunidad científica se está realizando sobre el COVID-19](https://www.whitehouse.gov/briefings-statements/call-action-tech-community-new-machine-readable-covid-19-dataset/). Muchas de estas preguntas están recogidas en la plataforma Kaggle ([https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks)), bien conocida por la comunidad de Ciencia de Datos e Inteligencia Artificial. Aquí se han formulado algunas de esas preguntas que se espera poder responder al procesar toda esta literatura científica. De hecho, a fecha de hoy (27 de marzo de 2020) hay más de 350 trabajos registrados donde se han hecho distintos tipos de tratamientos de los textos que han sido proporcionados.

En nuestro grupo llevamos trabajando varios años en el procesamiento de grandes corpus de textos, así que desde la semana pasada nos hemos puesto a trabajar para intentar aportar nuestro grano de arena en la solución de estos problemas. Os vamos a contar lo que hemos hecho hasta ahora, y los recursos que ponemos a disposición del resto de la comunidad científica, por si pueden resultar útiles. Asimismo, hacemos un llamamiento a todos aquellos que queráis colaborar con nosotros con nuevas preguntas, con la validación de los resultados que hemos obtenido hasta ahora, con la aplicación de nuevos algoritmos, o con cualquier otra cosa que se os ocurra. 

## Nuestra pregunta: ¿es posible relacionar de algún modo principios activos, grupos terapéuticos, pruebas, tratamientos y diagnósticos que se están reportando en la literatura científica?

La pregunta con la que hemos comenzado a trabajar es esta. Queremos ser capaces de ofrecer herramientas a la comunidad científica, así como a responsables de la gestión de la epidemia, que faciliten la navegación por el corpus para poder entender mejor qué tipos de tratamientos se han probado según lo reportado en la documentación científica, y así permitir entender mejor qué combinaciones de principios activos han sido probadas, lo que podría servir, por ejemplo, para definir nuevos protocolos clínicos de tratamiento para pacientes con algunas condiciones específicas.

Los servicios que hemos construido son la base sobre la que esperamos que este tipo de preguntas se puedan resolver. Aún queda mucho trabajo por hacer, sobre todo para proporcionar unas herramientas más cercanas a los usuarios finales. Por el momento nos hemos centrado en proporcionar las herramientas que otros desarrolladores también pueden utilizar para poder partir de un corpus ya refinado y anotado con una variedad de herramientas. 
